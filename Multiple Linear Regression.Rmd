---
title: "Coding Activity: Multiple Linear Regression"
author: "Aaron Tsui"
output: html_document
---

### Multiple Linear Regression (13 questions, 26 points)
In this activity, you will fit a linear regression model on two variables form a dataset and interpret the coefficients of those variables. Then you will use an interaction term to the model and interpret the model's fit. Next, you will fit a model on a categorical variable and interpret how the levels of a cartegorical variable can be interpreted. Finally, you will use two models to predict outcomes and compare their performance using a simple statistic, MSE.

Before you begin this activity, you may want to review your knowledge of simple (one predictor) linear regression. There is also an optional R activity covering this for you to use for review. This activity assumes familiarity with simple linear regression.

#### Introduction
Multiple Linear Regression involves the inclusion of any number of predictors, or covariates, into a linear model. The model learns the estimated contribution of each predictor in "explaining" the model's prediction of the outcome variable. These contributions are called the predictors' coefficients; one coefficient per predictor. We also refer to these coefficients as model parameters. It is these parameters, along with the intercept term that define a linear model, and are the result of fitting the model to a set of data. A learning algorithm finds the parameter and intercept values that maximize the model's fit to the data.

The general mathematical formula for a multiple linear regression model is:  
$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$$y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \cdots + \beta_{n} x_{n}$  
Where the $\beta_{0}$ term is the intercept, the $\beta_{i}$ symbols are the coefficients, or parameters, and the $x_{i}$ symbols are the predictors, or independent variables. The outcome, or dependent variable is $y$.

A linear model may contain one, some, or all of the variables in the data set. A model may also include "interaction" terms and non-linear terms. This makes linear regression a very flexible modeling technique. A flexible model can include many predictors and other terms and become very complex. Usually, you will try out different models to find the model or models that perform best. This is called "model selection". 

#### Overfitting
A more complex model tends to fit a dataset better than a simpler model because it has more flexibility. A model may fit the data well, but it runs the risk of losing generality, mainly because it is fitting the noise in the data set it is learning from. This is called "overfitting". A model's job is to discover a pattern in a set of data that describes a general trend in the real-world process being studied. If the model learned a general trend, it should be a good at predicting outcomes on a new set of data it hasn't "seen" before.

A model that has overfit is likely to have lost the ability to generalize as it has fit too closely to its specific training dataset, and will be a poor predictor when tested on new datasets. Therefore, the focus of modeling should not be on achieving a perfect fit. The best model is one that fits the data reasonably well while still performing well as a predictor.

A linear model may be used to study the effects of variables on each other and on the outcome variable as in many social science studies. A linear model may also be used solely to predict outcomes on new data. This latter use is more typical of commercial applications.

#### Dataset
The dataset we will use in this activity comes from a study of the effects of certain maternal characteristics, such as IQ, employment, and education, on their child's cognitive function as measure by a test of cognitive performance.
Ref: National Longitudinal Survey of Youth, A Program of the U.S. Bureau of Labor Statistics.

The data fields:
 kid_score - 3 and 4 year old children's scores on a cognitive test.
 mom_hs- 1 HS degree, 0 no HS degree.
 mom_iq- IQ test scores.
 mom_work- 1-4
          1- did not work in 1st three years of child's life.
          2- worked in second or third year of child's life.
          3- worked part-time in 1st year of child's life.
          4- worked full-time in first year of child's life.
 mom_age- in years.
 
Q1(2pts): Read in the data from the file "kidiq_data.csv". Display the header names and a summary of the data frame.
```{r}
df.child <- read.table("kidiq_data.csv", sep=",", header=TRUE)
summary(df.child)

```

Looking at the summary, and at the df.child dataframe in the Global Environment, you can see that all columns are numeric. Some of the columns could be said to be categorical, such as mom_hs and mom_work, but we will investigate that later in this activity.

##### An example with multiple covariates.
We'll make a model that predicts children's scores on a cognitive test from two covariates: mom_hs, and mom_iq. When specifying a model, we'll use a formula. In R, formulas are specified using a special syntax. You can find more on R formulas in the R Formula Syntax.pdf doc on Moodle, or by a web search.

The formula for our model:
kid_score ~ mom_hs + mom_iq

Linear regression is an "additive" model; the outcome is a linear combination of the predictors. The predictors are combined by the + symbol.

Q2(2pts): Using the formula above, fit a linear model using the df.child data set. Assign the result to a variable named "fit.1".
This is done with a call to the lm function (lm for "linear model"), passing in the formula above and the parameter: data=df.child.

```{r}
fit.1 <- lm(kid_score ~ mom_hs + mom_iq, data = df.child)
fit.1
```

A model with more than one predictor is more compilcated. How do we interpret the summary output of the fit? As with simple linear regression, the coefficients tell us the effect of a change in outcome for a change in one unit in the predictor, but we have to add that this is true when all other predictor values are held constant. 

The effect of a mom having a high school degree adds 5.95 points to her child's test score if we hold mom_iq constant. 

Q3(2pts): What is the effect on test scores for the same HS level of changing 1 point in IQ?
Write your answer after the arrow below.

> Test Scores increase by 0.5639.

Q4(2pts): The p-value Pr(>|t|) for each predictor is reported in the fit output. This is the result of a hypothesis test using a t-test statistic. What is the null hypothesis for these tests?
Write your answer after the arrow below.

> Ho : Mom IQ has no effect on Kid Test Scores.

##### Adding an interaction term.

It can be the case that some variables strongly interact with other variables. For example, the mom_hs variable has two values, 1= has a HS degree, 0= does not. It is quite likely, one might hypothesize, that the effect of any other variable would be different depending on whether or not their mother had a HS degree. Imagine dividing the data into two subsets based on the level of mom_hs. Following on from the previous model, we'll look at the effect of mom_iq for these two subsets to see if there is any interaction.

The following code is a plot of applying the model, fit.1, on both subsets: only mothers with HS, depicted by the grey points and for mothers who did not complete HS, depicted by the black points.
```{r}
plot(df.child$mom_iq, df.child$kid_score, xlab="Mother IQ score", 
  ylab="Child test score",pch=20, xaxt="n", yaxt="n", type="n")
curve (coef(fit.1)[1] + coef(fit.1)[2] + coef(fit.1)[3]*x, add=TRUE, col="gray")
curve (coef(fit.1)[1] + coef(fit.1)[3]*x, add=TRUE)
points (df.child$mom_iq[df.child$mom_hs==0], df.child$kid_score[df.child$mom_hs==0], pch=19)
points (df.child$mom_iq[df.child$mom_hs==1], df.child$kid_score[df.child$mom_hs==1], col="gray", pch=19)
axis (1, c(80,100,120,140))
axis (2, c(20,60,100,140))
```

The plot shows that the model slope does not differ for the two levels of mom_hs, yet the grey line is higher than the black line, indicating higher outcomes for mom_hs=1. The fact that the slopes are the same means the model is not allowing for any interaction between mom_hs and mom_iq.  If there was an interaction, we'd probably see a different slope for each subpopulation. In other words, the model is not accomodating this interaction, and therefore the model has the same slope for both subpopulations, when in reality they are probably different for each subpopulation.

Q5(2pts): Fit a linear model as above, but also includes an interaction term between mom_hs and mom_iq. Assign the model to a variable "fit.2". The interaction term can be written as mom_hs:mom_iq. You add the interaction term to the formula used in Q2 above, as well as the data=df.child parameter. Display a summary of the model fit.

```{r}
fit.2 <- lm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, data = df.child)
fit.2
```

A plot of the two populations as above but notice the slopes are allowed to vary. This confirms that there is an interaction between mom_hs and mom_iq.

```{r}
plot(df.child$mom_iq, df.child$kid_score, xlab="Mother IQ score",
  ylab="Child test score",pch=20, xaxt="n", yaxt="n", type="n")
curve (coef(fit.2)[1] + coef(fit.2)[2] + (coef(fit.2)[3] + coef(fit.2)[4])*x, add=TRUE, col="gray")
curve (coef(fit.2)[1] + coef(fit.2)[3]*x, add=TRUE)
points (df.child$mom_iq[df.child$mom_hs==0], df.child$kid_score[df.child$mom_hs==0], pch=20)
points (df.child$mom_iq[df.child$mom_hs==1], df.child$kid_score[df.child$mom_hs==1], col="gray", pch=20)
axis (1, c(80,100,120,140))
axis (2, c(20,60,100,140))
```

By adding an interaction term, we have made the model more flexible, but also more complex. We may be fitting the data slightly better, and we have learned something about the interaction of the variables. We may have made the model less general, and we would have to evaluate the models on their predictive perfoemance if we wanted to use them for that purpose.

##### Interpreting the interaction term.
Interpreting coefficients for a model with an interaction term is more complex. In the previous model, the unique effect of mom_iq on kid_score was not dependent on the value of mom_hs- it is assumed all predictors are independent of each other (we know this is not usually the case in real life, but we often ignore this to get simler models). In fit.2, the effect of mom_iq does depend on the value of mom_hs. This added dependency makes for a more complex model.

A summary of the interpretation of the fit2 model:

1-The intercept: effect when both mom_hs and mom_iq are 0. The latter is not meaningful as an IQ of zero does not exist, so we won't look at the intercept here. Note we are using the same units as the data for easier interpretation. The data could be standardized or otherwise transformed if needed.

2-The effect of mom_hs on kid_score is the difference between scores for mom_hs=0 and mom_iq=0 and mom_hs=1 and mom_iq=0. 

3-The effect of mom_iq on kid_score is the difference between mean scores for mom_hs=0 and mom_iq where mom_iq differs by one point. This is shown by the black line in the second plot.

4-The effect of the interaction term can be interpreted as the difference in the slope for mom_iq for mom_hs=0 and mom_hs=1. This is the slope difference between grey and black lines shown in the second plot.

The model (fit.2): kid_score = -11.48 + 51.27mom_hs + 0.97mom_iq - 0.48mom_hs:mom_iq  

When mom_hs=0 (black points in graph), 
kid_score = -11.48 + 51.27x0 + 0.97mom_iq - 0.48x0xmom_iq
          = -11.48 + 0.97mom_iq
          
When mom_hs=1 (grey points in graph),
kid_score = -11.48 + 51.27x1 + 0.97mom_iq - 0.48x1xmom_iq
          = -11.48 + 51.27 + 0.97mom_iq - 0.48mom_iq
          =  39.79 + 0.49mom_iq
          
The slopes, .97 for mom_hs=0, and .49 for mom_hs=1, for the lines of these two subpopulations are shown in the plot above.

There are a lot of possible values of IQ score, so you could plug in a sample of some IQ values to the formula to calculate the effect of those values on test scores. 

Q6(2pts): What score would be the result of mom_iq=100 for mom_hs=0? for mom_hs=1?

> mom_hs=0 = 96.89           mom_hs=1 = 96.89 + 51.2682 = 148.1582

This has been an exercise in fitting and interpreting linear regression models of several variables as well as adding an interaction term. We did not use all of the predictors in the dataset for simplicity. There are many possible combinations of predictors, and therefore models, possible, and that number grows very much larger if you add interaction and non-linear terms. What models you choose depends on the goals of your study. We will cover the topic of model selection by manual and by algorithmic means later on.

##### Categorical data.

As stated at the beginning, some of the variables in this dataset are actually categorical instead of numeric. Let's look at how categorical predictors work in a linear regression model.

Q7(2pts): Fit a linear model using kid_score as the outcome and mom_work as the only predictor. Use the correct R formula and don't forget the data parameter. Display the summary.
```{r}
# No variable name was specified for this problem, so I just used mwpred (mom work predictor).
mwpred <- lm(kid_score ~ mom_work, data=df.child)
summary(mwpred)
```

Q8(2pts): What does the coefficient say about the effect on average of an increase of 1 unit of mom_work on kid_score? State direction (increase or decrease) and magnitude.

> kid_score increases by 1.512.

From the description of the mom_work field at the top of the page, and by looking at the summary stats for that variable in the dataframe, it is clear that the mom_work variable is categorical with levels 1, 2, 3, 4. Next, let's fit a model with mom_work as a categorical predictor.

Q9(2pts): Fit a linear model using kid_score as a function of mom_work, except that this time use the as.factor function to make mom_work a categorical variable in the model. Note that this does not change the mom_work column in the dataframe df.child.
Assign the call to lm to the variable fit.cat and display the summary of the fitted object.

```{r}
fit.cat <- lm( kid_score ~ as.factor(mom_work), data = df.child)
summary(fit.cat)
```

Note that the fit output has three entries for mom_work, one for levels 2, 3, and 4. The way to interpret this output is that the first level of mom_work, 1, is treated as the base value. The average score predicted if mom_work = 1 would be the intercept, 82 (Remember that the intercept is the model prediction if the value of all variables are zero. In this case the base is a category, 1, instead of 0). The prediction for the other values is their coefficient plus the intercept. 

Q10(2pts): Which of the levels of mom_work predicts the highest average score? What is that score? Given the description of this level of mom_work (at the top of the page), can you come up with one sentence that might explain this result?

> Level 3. A probable explanation for this is that moms that only worked part-time the first year of their child's life are both financially able to take time off and have a job, which could indicate the parents having attended higher levels of education. Parents that have gone to college typically encourage their children to do so too, which may result in higher average IQ. 

###### Model Evaluation
Now we'll look at how to evaluate a linear model's ability to predict outcomes. We will use a subset of the data, say 80%, to fit the model, i.e. 'train" the model, and reserve about 20% of the data to use as a test set. The reason for doing this is because the model is tested on data that it was not fitted on. In theory, this should provide a more valid test of the model because it hasn't "seen" the test data. 

The following code creates a training and testing set according to the 80-20 proportion. The bracket notation is one way to select rows and columns for a data frame. In this case, we want to select a specific sequence of rows and all columns. 
(The R operator : is used to specify a sequence of integers. To see this, type 1:20 in the R console below and see what happens). In the future, we will use random selection for training and testing sets.

```{r}
train.data<- df.child[1:344,]
test.data<- df.child[345:434,]
```

Q11(2pts): Write two statements, one that fits the linear model with kid_score as dependent variable and mom_hs and mom_iq as independent variables, and another that adds an interaction term between mom_hs and mom_iq. Fit these two models to the training set created above (use the data= parameter to select the training dataframe). Call the fit variables fit.3 and fit.4, respectively, then display the summary of both fit objects.

```{r}
fit.3 <- lm(kid_score ~ mom_hs + mom_iq, data=df.child)
fit.4 <- lm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, data=df.child)
summary(fit.3)
summary(fit.4)
```

Q12(2pts): What are the Adjusted R-squared values for fit.3 nd fit.4? Using the Adjusted R-squared values as a measure of "goodness" of fit, which model is a better fit to the training data?
Write your answers after the arrow below:

>fit.3: 0.2105
>fit.4: 0.2247


##### Evaluate predictions.

This code creates predictions for both models.
```{r}
pred.3<-predict (fit.3, test.data, interval="prediction", level=0.95)
pred.4<-predict (fit.4, test.data, interval="prediction", level=0.95)
```

Since the output of a linear regression model is a real number, we don't expect to get a correct point prediction. Intead, we calculate an error statistic on all rows in the test data. A simple statistic is the mean squared error (MSE).
    MSE = mean((actual_scores - predicted_scores)^2)

Notice the use of brackets to select the first column from the test dataset, which are the actual outcomes.
Also, bracket notation is used to get the model's predictions from the pred objects. In R, most objects' data can be accessed by an index number or by names. In the case of pred objects, you have to use an index number. To see the contents of a pred object, type the object's name in the R console below (not in the Rmd file). You can see the model's prediction fit, and lower and upper bounds for each row in the test set.

```{r}
actual_scores<-test.data[,1]
pred.vals.3<-pred.3[,1]
pred.vals.4<-pred.4[,1]
mse.fit.3 <- mean((actual_scores - pred.vals.3)^2)
mse.fit.4 <- mean((actual_scores - pred.vals.4)^2)
```

Q13(2pts): Which model do you think is a better predictor?

> I think model 4 is the better predictor, because its adjusted R-squared value explains more of the variability of kid_score than model 3 does. It also has lower residual standard error, which means the regression line fits the data better.

